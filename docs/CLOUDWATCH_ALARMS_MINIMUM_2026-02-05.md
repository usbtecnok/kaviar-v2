# CloudWatch Alarms - Kaviar Production

**Data:** 2026-02-05  
**RegiÃ£o:** us-east-2  
**SNS Topic:** arn:aws:sns:us-east-2:847895361928:kaviar-alerts

---

## ðŸ“Š Recursos Monitorados

### ECS
- **Cluster:** kaviar-cluster
- **Service:** kaviar-backend-service
- **Desired Count:** 2 tasks

### ALB
- **Name:** kaviar-alb
- **ARN:** arn:aws:elasticloadbalancing:us-east-2:847895361928:loadbalancer/app/kaviar-alb/a3ea4728f211b6c7
- **Target Group:** kaviar-backend-tg

### RDS
- **Instance:** kaviar-prod-db
- **Engine:** PostgreSQL 15.15
- **Multi-AZ:** Yes
- **ARN:** arn:aws:rds:us-east-2:847895361928:db:kaviar-prod-db

### Logs
- **Log Group:** /ecs/kaviar-backend

---

## ðŸš¨ Alarms Criados

### 1. KAVIAR-PROD-ECS-RunningTasks-Low
**MÃ©trica:** ECS/ContainerInsights - RunningTaskCount  
**Threshold:** < 2 tasks  
**PerÃ­odo:** 2 minutos (2 x 60s)  
**AÃ§Ã£o:** Notificar via SNS  
**TreatMissingData:** notBreaching âœ… (corrigido)

**Comando de criaÃ§Ã£o:**
```bash
aws cloudwatch put-metric-alarm \
  --region us-east-2 \
  --alarm-name KAVIAR-PROD-ECS-RunningTasks-Low \
  --alarm-description "ECS running tasks below desired count" \
  --metric-name RunningTaskCount \
  --namespace ECS/ContainerInsights \
  --statistic Average \
  --period 60 \
  --evaluation-periods 2 \
  --threshold 2 \
  --comparison-operator LessThanThreshold \
  --dimensions Name=ServiceName,Value=kaviar-backend-service Name=ClusterName,Value=kaviar-cluster \
  --alarm-actions arn:aws:sns:us-east-2:847895361928:kaviar-alerts \
  --treat-missing-data notBreaching
```

**Nota:** Corrigido de `breaching` para `notBreaching` para evitar falsos positivos quando ContainerInsights nÃ£o envia datapoints.

---

### 2. KAVIAR-PROD-RDS-CPU-High
**MÃ©trica:** AWS/RDS - CPUUtilization  
**Threshold:** > 70%  
**PerÃ­odo:** 10 minutos (1 x 600s)  
**AÃ§Ã£o:** Notificar via SNS  

**Comando de criaÃ§Ã£o:**
```bash
aws cloudwatch put-metric-alarm \
  --region us-east-2 \
  --alarm-name KAVIAR-PROD-RDS-CPU-High \
  --alarm-description "RDS CPU utilization above 70%" \
  --metric-name CPUUtilization \
  --namespace AWS/RDS \
  --statistic Average \
  --period 600 \
  --evaluation-periods 1 \
  --threshold 70 \
  --comparison-operator GreaterThanThreshold \
  --dimensions Name=DBInstanceIdentifier,Value=kaviar-prod-db \
  --alarm-actions arn:aws:sns:us-east-2:847895361928:kaviar-alerts
```

---

### 3. KAVIAR-PROD-RDS-Connections-High
**MÃ©trica:** AWS/RDS - DatabaseConnections  
**Threshold:** > 50 connections  
**PerÃ­odo:** 10 minutos (2 x 300s)  
**AÃ§Ã£o:** Notificar via SNS  

**Comando de criaÃ§Ã£o:**
```bash
aws cloudwatch put-metric-alarm \
  --region us-east-2 \
  --alarm-name KAVIAR-PROD-RDS-Connections-High \
  --alarm-description "RDS database connections above 50" \
  --metric-name DatabaseConnections \
  --namespace AWS/RDS \
  --statistic Average \
  --period 300 \
  --evaluation-periods 2 \
  --threshold 50 \
  --comparison-operator GreaterThanThreshold \
  --dimensions Name=DBInstanceIdentifier,Value=kaviar-prod-db \
  --alarm-actions arn:aws:sns:us-east-2:847895361928:kaviar-alerts
```

**Nota:** Threshold conservador (50) para db.t3.micro (max ~85 connections).

---

### 4. KAVIAR-PROD-ALB-Target5XX-High
**MÃ©trica:** AWS/ApplicationELB - HTTPCode_Target_5XX_Count  
**Threshold:** > 1 error  
**PerÃ­odo:** 5 minutos (1 x 300s)  
**AÃ§Ã£o:** Notificar via SNS  

**Comando de criaÃ§Ã£o:**
```bash
aws cloudwatch put-metric-alarm \
  --region us-east-2 \
  --alarm-name KAVIAR-PROD-ALB-Target5XX-High \
  --alarm-description "ALB target 5XX errors above threshold" \
  --metric-name HTTPCode_Target_5XX_Count \
  --namespace AWS/ApplicationELB \
  --statistic Sum \
  --period 300 \
  --evaluation-periods 1 \
  --threshold 1 \
  --comparison-operator GreaterThanThreshold \
  --dimensions Name=LoadBalancer,Value=app/kaviar-alb/a3ea4728f211b6c7 \
  --alarm-actions arn:aws:sns:us-east-2:847895361928:kaviar-alerts \
  --treat-missing-data notBreaching
```

---

### 5. KAVIAR-PROD-Logs-Errors-High
**MÃ©trica:** Kaviar/Logs - ErrorCount (custom)  
**Threshold:** > 5 errors  
**PerÃ­odo:** 5 minutos (1 x 300s)  
**AÃ§Ã£o:** Notificar via SNS  

**Metric Filter:**
```bash
aws logs put-metric-filter \
  --region us-east-2 \
  --log-group-name /ecs/kaviar-backend \
  --filter-name KAVIAR-PROD-ErrorCount \
  --filter-pattern '?ERROR ?Unhandled ?Exception ?Prisma' \
  --metric-transformations \
    metricName=ErrorCount,metricNamespace=Kaviar/Logs,metricValue=1,defaultValue=0
```

**Alarm:**
```bash
aws cloudwatch put-metric-alarm \
  --region us-east-2 \
  --alarm-name KAVIAR-PROD-Logs-Errors-High \
  --alarm-description "Application errors in logs above threshold" \
  --metric-name ErrorCount \
  --namespace Kaviar/Logs \
  --statistic Sum \
  --period 300 \
  --evaluation-periods 1 \
  --threshold 5 \
  --comparison-operator GreaterThanThreshold \
  --alarm-actions arn:aws:sns:us-east-2:847895361928:kaviar-alerts \
  --treat-missing-data notBreaching
```

---

## âœ… VerificaÃ§Ã£o

### Listar todos os alarms:
```bash
aws cloudwatch describe-alarms \
  --region us-east-2 \
  --alarm-name-prefix KAVIAR-PROD- \
  --query 'MetricAlarms[*].[AlarmName,StateValue,MetricName]' \
  --output table
```

### Verificar SNS subscriptions:
```bash
aws sns list-subscriptions-by-topic \
  --region us-east-2 \
  --topic-arn arn:aws:sns:us-east-2:847895361928:kaviar-alerts
```

### Testar notificaÃ§Ã£o:
```bash
aws sns publish \
  --region us-east-2 \
  --topic-arn arn:aws:sns:us-east-2:847895361928:kaviar-alerts \
  --subject "Test Alert" \
  --message "CloudWatch alarms configured successfully"
```

---

## ðŸ“‹ Resumo

| Alarm | MÃ©trica | Threshold | PerÃ­odo | Status |
|-------|---------|-----------|---------|--------|
| ECS-RunningTasks-Low | RunningTaskCount | < 2 | 2 min | âœ… Criado |
| RDS-CPU-High | CPUUtilization | > 70% | 10 min | âœ… Criado |
| RDS-Connections-High | DatabaseConnections | > 50 | 10 min | âœ… Criado |
| ALB-Target5XX-High | HTTPCode_Target_5XX_Count | > 1 | 5 min | âœ… Criado |
| Logs-Errors-High | ErrorCount (custom) | > 5 | 5 min | âœ… Criado |

**Total:** 5 alarms + 1 metric filter  
**SNS Topic:** kaviar-alerts (jÃ¡ existente)  
**RegiÃ£o:** us-east-2
